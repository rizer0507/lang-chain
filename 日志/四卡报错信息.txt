(APIServer pid=1) INFO 01-16 17:13:56 [chat_utils.py:560] Detected the chat template content format to be 'openai'. You can set `--chat-template-content-format` to override this.
(APIServer pid=1) INFO 01-16 17:13:56 [logger.py:40] Received request chatcmpl-bc82b57f57064cdcbddd1d0af86398ae: prompt: '<|im_start|>system\n你是一个有用的助手。你会通过 message_save 工具保存答案到文件。\n\n工作流程：\n1. 当你第一次回答用户问题时，生成完整的中文答案，并将其作为 prompt 参数传递给 message_save 工具\n2. message_save 工具会将答案保存到文件并返回确认信息\n3. 看到工具返回后，将同样的答案直接输出给用户\n\n注意：\n- 第一次输出时将完整答案放在 message_save 的 prompt 参数中\n- 工具返回后，直接输出答案内容给用户（不要再次调用工具）<|im_end|>\n<|im_start|>user\n请用中文简单介绍一下人工智能的历史，控制在100字以内。<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=False, spaces_between_special_tokens=True, truncate_prompt_tokens=None, structured_outputs=StructuredOutputsParams(json={'properties': {'prompt': {'type': 'string'}}, 'required': ['prompt'], 'type': 'object'}, regex=None, choice=None, grammar=None, json_object=None, disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, whitespace_pattern=None, structural_tag=None, _backend=None, _backend_was_auto=False), extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None.
(APIServer pid=1) INFO 01-16 17:13:56 [async_llm.py:316] Added request chatcmpl-bc82b57f57064cdcbddd1d0af86398ae.
(APIServer pid=1) INFO 01-16 17:14:18 [loggers.py:127] Engine 000: Avg prompt throughput: 15.0 tokens/s, Avg generation throughput: 0.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
(APIServer pid=1) INFO:     192.168.1.253:51352 - "POST /v1/chat/completions HTTP/1.1" 200 OK
(APIServer pid=1) INFO 01-16 17:14:21 [logger.py:40] Received request chatcmpl-09543f8fa6b94b0791b5eded8b399db4: prompt: '<|im_start|>system\n你是一个有用的助手。你会通过 message_save 工具保存答案到文件。\n\n工作流程：\n1. 当你第一次回答用户问题时，生成完整的中文答案，并将其作为 prompt 参数传递给 message_save 工具\n2. message_save 工具会将答案保存到文件并返回确认信息\n3. 看到工具返回后，将同样的答案直接输出给用户\n\n注意：\n- 第一次输出时将完整答案放在 message_save 的 prompt 参数中\n- 工具返回后，直接输出答案内容给用户（不要再次调用工具）<|im_end|>\n<|im_start|>user\n请用中文简单介绍一下人工智能的历史，控制在100字以内。<|im_end|>\n<|im_start|>assistant\n<|im_end|>\n<|im_start|>tool\n已成功保存到文件: /home/langchain_agent_logs/answer_20260116_171421.txt<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, structured_outputs=None, extra_args=None), prompt_token_ids: None, prompt_embeds shape: None, lora_request: None.
(APIServer pid=1) INFO 01-16 17:14:21 [async_llm.py:316] Added request chatcmpl-09543f8fa6b94b0791b5eded8b399db4.
(APIServer pid=1) INFO 01-16 17:14:28 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 8.1 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671] WorkerProc hit an exception.
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671] Traceback (most recent call last):
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/executor/multiproc_executor.py", line 666, in worker_busy_loop
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     output = func(*args, **kwargs)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]              ^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return func(*args, **kwargs)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_worker.py", line 447, in execute_model
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     output = self.model_runner.execute_model(scheduler_output,
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return func(*args, **kwargs)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_model_runner.py", line 2257, in execute_model
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     ) = self._prepare_inputs(scheduler_output)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_model_runner.py", line 1252, in _prepare_inputs
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     attn_metadata_i = builder.build(
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]                       ^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/attention/backends/flex_attention.py", line 620, in build
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     out = FlexAttentionMetadata(
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]           ^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "<string>", line 33, in __init__
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/attention/backends/flex_attention.py", line 553, in __post_init__
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     self.block_mask = self.build_block_mask()
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]                       ^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/attention/backends/flex_attention.py", line 527, in build_block_mask
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return create_block_mask_compiled(
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 736, in compile_wrapper
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return fn(*args, **kwargs)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/attention/flex_attention.py", line 832, in create_block_mask
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     def create_block_mask(
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 929, in _fn
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return fn(*args, **kwargs)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1241, in forward
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return compiled_fn(full_args)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 384, in runtime_wrapper
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     all_outs = call_func_at_runtime_with_args(
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 126, in call_func_at_runtime_with_args
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     out = normalize_as_list(f(args))
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]                             ^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 750, in inner_fn
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     outs = compiled_fn(args)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 556, in wrapper
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return compiled_fn(runtime_args)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 584, in __call__
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return self.current_callable(inputs)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671] WorkerProc hit an exception.
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671] Traceback (most recent call last):
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/executor/multiproc_executor.py", line 666, in worker_busy_loop
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     output = func(*args, **kwargs)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]              ^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return func(*args, **kwargs)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_worker.py", line 447, in execute_model
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     output = self.model_runner.execute_model(scheduler_output,
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return func(*args, **kwargs)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_model_runner.py", line 2257, in execute_model
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     ) = self._prepare_inputs(scheduler_output)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_model_runner.py", line 1252, in _prepare_inputs
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     attn_metadata_i = builder.build(
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]                       ^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/attention/backends/flex_attention.py", line 620, in build
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     out = FlexAttentionMetadata(
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]           ^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "<string>", line 33, in __init__
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/attention/backends/flex_attention.py", line 553, in __post_init__
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     self.block_mask = self.build_block_mask()
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]                       ^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/attention/backends/flex_attention.py", line 527, in build_block_mask
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return create_block_mask_compiled(
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 736, in compile_wrapper
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return fn(*args, **kwargs)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/attention/flex_attention.py", line 832, in create_block_mask
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     def create_block_mask(
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 929, in _fn
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return fn(*args, **kwargs)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1241, in forward
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return compiled_fn(full_args)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 384, in runtime_wrapper
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     all_outs = call_func_at_runtime_with_args(
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 126, in call_func_at_runtime_with_args
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     out = normalize_as_list(f(args))
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]                             ^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 750, in inner_fn
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     outs = compiled_fn(args)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 556, in wrapper
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return compiled_fn(runtime_args)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 584, in __call__
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return self.current_callable(inputs)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1655, in run
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return compiled_fn(new_inputs)  # type: ignore[arg-type]
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/cudagraph_trees.py", line 403, in deferred_cudagraphify
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     fn, out = cudagraphify(model, inputs, new_static_input_idxs, *args, **kwargs)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/cudagraph_trees.py", line 462, in cudagraphify
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return manager.add_function(
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/cudagraph_trees.py", line 2316, in add_function
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return fn, fn(inputs)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]                ^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/cudagraph_trees.py", line 2012, in run
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     out = self._run(new_inputs, function_id)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/cudagraph_trees.py", line 2116, in _run
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return self.run_eager(new_inputs, function_id)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/cudagraph_trees.py", line 2277, in run_eager
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return node.run(new_inputs)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/cudagraph_trees.py", line 685, in run
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     out = self.wrapped_function.model(new_inputs)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/tmp/torchinductor_root/vm/cvm7jcn6opfvqharvry4gksxfgij7qc3u4qgiy5eec26h3d4sapv.py", line 609, in call
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     triton_per_fused__to_copy_sum_8.run(buf20, buf24, 11575, triton_per_fused__to_copy_sum_8_r0_numel, stream=stream2)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1133, in run
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     self.autotune_to_one_config(*args, **kwargs)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 960, in autotune_to_one_config
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     timings = self.benchmark_all_configs(*args, **kwargs)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 935, in benchmark_all_configs
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     launcher: self.bench(launcher, *args, **kwargs)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 804, in bench
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return benchmarker.benchmark_gpu(kernel_call, rep=40)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 39, in wrapper
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return fn(self, *args, **kwargs)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 244, in benchmark_gpu
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     torch.cuda.synchronize()
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py", line 1085, in synchronize
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return torch._C._cuda_synchronize()
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671] torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671] CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671] For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671] Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671] Traceback (most recent call last):
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/executor/multiproc_executor.py", line 666, in worker_busy_loop
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     output = func(*args, **kwargs)
(Worker_TP2 pid=466) (Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1655, in run
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return compiled_fn(new_inputs)  # type: ignore[arg-type]
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/cudagraph_trees.py", line 403, in deferred_cudagraphify
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     fn, out = cudagraphify(model, inputs, new_static_input_idxs, *args, **kwargs)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/cudagraph_trees.py", line 462, in cudagraphify
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return manager.add_function(
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/cudagraph_trees.py", line 2316, in add_function
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return fn, fn(inputs)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]                ^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/cudagraph_trees.py", line 2012, in run
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     out = self._run(new_inputs, function_id)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/cudagraph_trees.py", line 2116, in _run
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return self.run_eager(new_inputs, function_id)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/cudagraph_trees.py", line 2277, in run_eager
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return node.run(new_inputs)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/cudagraph_trees.py", line 685, in run
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     out = self.wrapped_function.model(new_inputs)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/tmp/torchinductor_root/tz/ctz7lgcbvazrpqz2avwejmdqgfdso53vdqjrajinhjz4kioz3zrp.py", line 609, in call
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     triton_per_fused__to_copy_sum_8.run(buf20, buf24, 11575, triton_per_fused__to_copy_sum_8_r0_numel, stream=stream3)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1133, in run
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     self.autotune_to_one_config(*args, **kwargs)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 960, in autotune_to_one_config
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     timings = self.benchmark_all_configs(*args, **kwargs)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 935, in benchmark_all_configs
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     launcher: self.bench(launcher, *args, **kwargs)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 804, in bench
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return benchmarker.benchmark_gpu(kernel_call, rep=40)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 39, in wrapper
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return fn(self, *args, **kwargs)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 244, in benchmark_gpu
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     torch.cuda.synchronize()
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py", line 1085, in synchronize
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return torch._C._cuda_synchronize()
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671] torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671] CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671] For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671] Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671] Traceback (most recent call last):
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/executor/multiproc_executor.py", line 666, in worker_busy_loop
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     output = func(*args, **kwargs)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]              ^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return func(*args, **kwargs)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_worker.py", line 447, in execute_model
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     output = self.model_runner.execute_model(scheduler_output,
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return func(*args, **kwargs)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_model_runner.py", line 2257, in execute_model
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     ) = self._prepare_inputs(scheduler_output)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_model_runner.py", line 1252, in _prepare_inputs
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     attn_metadata_i = builder.build(
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]                       ^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/attention/backends/flex_attention.py", line 620, in build
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     out = FlexAttentionMetadata(
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]           ^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "<string>", line 33, in __init__
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/attention/backends/flex_attention.py", line 553, in __post_init__
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     self.block_mask = self.build_block_mask()
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]                       ^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/attention/backends/flex_attention.py", line 527, in build_block_mask
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return create_block_mask_compiled(
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 736, in compile_wrapper
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return fn(*args, **kwargs)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/attention/flex_attention.py", line 832, in create_block_mask
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     def create_block_mask(
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 929, in _fn
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return fn(*args, **kwargs)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1241, in forward
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return compiled_fn(full_args)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 384, in runtime_wrapper
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     all_outs = call_func_at_runtime_with_args(
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 126, in call_func_at_runtime_with_args
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     out = normalize_as_list(f(args))
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]                             ^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 750, in inner_fn
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     outs = compiled_fn(args)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 556, in wrapper
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return compiled_fn(runtime_args)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 584, in __call__
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return self.current_callable(inputs)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1655, in run
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return compiled_fn(new_inputs)  # type: ignore[arg-type]
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/cudagraph_trees.py", line 403, in deferred_cudagraphify
ERROR 01-16 17:14:29 [multiproc_executor.py:671]              ^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return func(*args, **kwargs)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_worker.py", line 447, in execute_model
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     output = self.model_runner.execute_model(scheduler_output,
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return func(*args, **kwargs)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_model_runner.py", line 2257, in execute_model
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     ) = self._prepare_inputs(scheduler_output)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/worker/gpu_model_runner.py", line 1252, in _prepare_inputs
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     attn_metadata_i = builder.build(
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]                       ^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/attention/backends/flex_attention.py", line 620, in build
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     out = FlexAttentionMetadata(
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]           ^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "<string>", line 33, in __init__
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/attention/backends/flex_attention.py", line 553, in __post_init__
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     self.block_mask = self.build_block_mask()
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]                       ^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/attention/backends/flex_attention.py", line 527, in build_block_mask
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return create_block_mask_compiled(
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 736, in compile_wrapper
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return fn(*args, **kwargs)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/attention/flex_attention.py", line 832, in create_block_mask
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     def create_block_mask(
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 929, in _fn
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return fn(*args, **kwargs)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1241, in forward
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return compiled_fn(full_args)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 384, in runtime_wrapper
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     all_outs = call_func_at_runtime_with_args(
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 126, in call_func_at_runtime_with_args
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     out = normalize_as_list(f(args))
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]                             ^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 750, in inner_fn
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     outs = compiled_fn(args)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 556, in wrapper
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return compiled_fn(runtime_args)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 584, in __call__
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return self.current_callable(inputs)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1655, in run
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return compiled_fn(new_inputs)  # type: ignore[arg-type]
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/cudagraph_trees.py", line 403, in deferred_cudagraphify
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     fn, out = cudagraphify(model, inputs, new_static_input_idxs, *args, **kwargs)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/cudagraph_trees.py", line 462, in cudagraphify
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return manager.add_function(
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/cudagraph_trees.py", line 2316, in add_function
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return fn, fn(inputs)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]                ^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/cudagraph_trees.py", line 2012, in run
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     out = self._run(new_inputs, function_id)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/cudagraph_trees.py", line 2116, in _run
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return self.run_eager(new_inputs, function_id)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/cudagraph_trees.py", line 2277, in run_eager
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return node.run(new_inputs)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/cudagraph_trees.py", line 685, in run
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     out = self.wrapped_function.model(new_inputs)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/tmp/torchinductor_root/vm/cvm7jcn6opfvqharvry4gksxfgij7qc3u4qgiy5eec26h3d4sapv.py", line 609, in call
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     triton_per_fused__to_copy_sum_8.run(buf20, buf24, 11575, triton_per_fused__to_copy_sum_8_r0_numel, stream=stream2)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1133, in run
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     self.autotune_to_one_config(*args, **kwargs)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 960, in autotune_to_one_config
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     timings = self.benchmark_all_configs(*args, **kwargs)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 935, in benchmark_all_configs
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     launcher: self.bench(launcher, *args, **kwargs)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 804, in bench
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return benchmarker.benchmark_gpu(kernel_call, rep=40)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 39, in wrapper
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return fn(self, *args, **kwargs)
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 244, in benchmark_gpu
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     torch.cuda.synchronize()
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py", line 1085, in synchronize
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return torch._C._cuda_synchronize()
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671] torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671] CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671] For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671] Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]
(Worker_TP2 pid=466) ERROR 01-16 17:14:29 [multiproc_executor.py:671]
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     fn, out = cudagraphify(model, inputs, new_static_input_idxs, *args, **kwargs)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/cudagraph_trees.py", line 462, in cudagraphify
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return manager.add_function(
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/cudagraph_trees.py", line 2316, in add_function
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return fn, fn(inputs)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]                ^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/cudagraph_trees.py", line 2012, in run
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     out = self._run(new_inputs, function_id)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/cudagraph_trees.py", line 2116, in _run
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return self.run_eager(new_inputs, function_id)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/cudagraph_trees.py", line 2277, in run_eager
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return node.run(new_inputs)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/cudagraph_trees.py", line 685, in run
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     out = self.wrapped_function.model(new_inputs)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/tmp/torchinductor_root/tz/ctz7lgcbvazrpqz2avwejmdqgfdso53vdqjrajinhjz4kioz3zrp.py", line 609, in call
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     triton_per_fused__to_copy_sum_8.run(buf20, buf24, 11575, triton_per_fused__to_copy_sum_8_r0_numel, stream=stream3)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1133, in run
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     self.autotune_to_one_config(*args, **kwargs)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 960, in autotune_to_one_config
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     timings = self.benchmark_all_configs(*args, **kwargs)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 935, in benchmark_all_configs
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     launcher: self.bench(launcher, *args, **kwargs)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 804, in bench
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return benchmarker.benchmark_gpu(kernel_call, rep=40)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 39, in wrapper
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return fn(self, *args, **kwargs)
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 244, in benchmark_gpu
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     torch.cuda.synchronize()
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]   File "/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py", line 1085, in synchronize
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]     return torch._C._cuda_synchronize()
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671] torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671] CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671] For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671] Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]
(Worker_TP3 pid=467) ERROR 01-16 17:14:29 [multiproc_executor.py:671]
(APIServer pid=1) INFO 01-16 17:14:38 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%

(EngineCore_DP0 pid=331) INFO 01-16 17:15:21 [shm_broadcast.py:466] No available shared memory broadcast block found in 60 seconds. This typically happens when some processes are hanging or doing some time-consuming work (e.g. compilation).
(EngineCore_DP0 pid=331) INFO 01-16 17:16:21 [shm_broadcast.py:466] No available shared memory broadcast block found in 60 seconds. This typically happens when some processes are hanging or doing some time-consuming work (e.g. compilation).
(EngineCore_DP0 pid=331) INFO 01-16 17:17:21 [shm_broadcast.py:466] No available shared memory broadcast block found in 60 seconds. This typically happens when some processes are hanging or doing some time-consuming work (e.g. compilation).
(EngineCore_DP0 pid=331) INFO 01-16 17:18:21 [shm_broadcast.py:466] No available shared memory broadcast block found in 60 seconds. This typically happens when some processes are hanging or doing some time-consuming work (e.g. compilation).
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [dump_input.py:69] Dumping input data for V1 LLM engine (v0.11.0) with config: model='/root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac', speculative_config=None, tokenizer='/root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir='/root/.cache/huggingface', load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen2-VL-7B-Instruct, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":null,"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":0,"use_cudagraph":true,"cudagraph_num_of_warmups":0,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":0,"local_cache_dir":null},
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [dump_input.py:76] Dumping scheduler output for model execution: SchedulerOutput(scheduled_new_reqs=[NewRequestData(req_id=chatcmpl-09543f8fa6b94b0791b5eded8b399db4,prompt_token_ids_len=191,mm_features=[],sampling_params=SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[151643], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, structured_outputs=None, extra_args=None),block_ids=([1, 2, 3, 4, 5, 6, 7, 8, 9, 16, 17, 18],),num_computed_tokens=144,lora_request=None,prompt_embeds_shape=None)], scheduled_cached_reqs=CachedRequestData(req_ids=[], resumed_from_preemption=[], new_token_ids=[], new_block_ids=[], num_computed_tokens=[]), num_scheduled_tokens={chatcmpl-09543f8fa6b94b0791b5eded8b399db4: 47}, total_num_scheduled_tokens=47, scheduled_spec_decode_tokens={}, scheduled_encoder_inputs={}, num_common_prefix_blocks=[12], finished_req_ids=[], free_encoder_mm_hashes=[], structured_output_request_ids={}, grammar_bitmask=null, kv_connector_metadata=null)
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [dump_input.py:79] Dumping scheduler stats: SchedulerStats(num_running_reqs=1, num_waiting_reqs=0, step_counter=0, current_wave=0, kv_cache_usage=0.00012959663048761616, prefix_cache_stats=PrefixCacheStats(reset=False, requests=1, queries=191, hits=144), spec_decoding_stats=None, kv_connector_stats=None, num_corrupted_reqs=0)
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710] EngineCore encountered a fatal error.
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710] Traceback (most recent call last):
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/executor/multiproc_executor.py", line 264, in collective_rpc
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]     result = get_response(w, dequeue_timeout,
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/executor/multiproc_executor.py", line 244, in get_response
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]     status, result = w.worker_response_mq.dequeue(
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]   File "/usr/local/lib/python3.12/dist-packages/vllm/distributed/device_communicators/shm_broadcast.py", line 511, in dequeue
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]     with self.acquire_read(timeout, cancel, indefinite) as buf:
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]   File "/usr/lib/python3.12/contextlib.py", line 137, in __enter__
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]     return next(self.gen)
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]            ^^^^^^^^^^^^^^
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]   File "/usr/local/lib/python3.12/dist-packages/vllm/distributed/device_communicators/shm_broadcast.py", line 460, in acquire_read
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]     raise TimeoutError
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710] TimeoutError
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710] The above exception was the direct cause of the following exception:
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710] Traceback (most recent call last):
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 701, in run_engine_core
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]     engine_core.run_busy_loop()
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 728, in run_busy_loop
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]     self._process_engine_step()
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 754, in _process_engine_step
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]     outputs, model_executed = self.step_fn()
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]                               ^^^^^^^^^^^^^^
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 284, in step
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]     model_output = self.execute_model_with_error_logging(
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 270, in execute_model_with_error_logging
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]     raise err
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core.py", line 261, in execute_model_with_error_logging
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]     return model_fn(scheduler_output)
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]            ^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/executor/multiproc_executor.py", line 181, in execute_model
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]     (output, ) = self.collective_rpc(
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]                  ^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/executor/multiproc_executor.py", line 273, in collective_rpc
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710]     raise TimeoutError(f"RPC call to {method} timed out.") from e
(EngineCore_DP0 pid=331) ERROR 01-16 17:19:21 [core.py:710] TimeoutError: RPC call to execute_model timed out.
(APIServer pid=1) ERROR 01-16 17:19:21 [async_llm.py:480] AsyncLLM output_handler failed.
(APIServer pid=1) ERROR 01-16 17:19:21 [async_llm.py:480] Traceback (most recent call last):
(APIServer pid=1) ERROR 01-16 17:19:21 [async_llm.py:480]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/async_llm.py", line 439, in output_handler
(APIServer pid=1) ERROR 01-16 17:19:21 [async_llm.py:480]     outputs = await engine_core.get_output_async()
(APIServer pid=1) ERROR 01-16 17:19:21 [async_llm.py:480]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(APIServer pid=1) ERROR 01-16 17:19:21 [async_llm.py:480]   File "/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/core_client.py", line 846, in get_output_async
(APIServer pid=1) ERROR 01-16 17:19:21 [async_llm.py:480]     raise self._format_exception(outputs) from None
(APIServer pid=1) ERROR 01-16 17:19:21 [async_llm.py:480] vllm.v1.engine.exceptions.EngineDeadError: EngineCore encountered an issue. See stack trace (above) for the root cause.
(APIServer pid=1) INFO 01-16 17:19:21 [async_llm.py:406] Request chatcmpl-09543f8fa6b94b0791b5eded8b399db4 failed (engine dead).
(Worker_TP2 pid=466) INFO 01-16 17:19:21 [multiproc_executor.py:558] Parent process exited, terminating worker
(APIServer pid=1) INFO:     192.168.1.253:51352 - "POST /v1/chat/completions HTTP/1.1" 500 Internal Server Error
(Worker_TP3 pid=467) INFO 01-16 17:19:21 [multiproc_executor.py:558] Parent process exited, terminating worker
(APIServer pid=1) INFO:     192.168.1.253:51352 - "POST /v1/chat/completions HTTP/1.1" 500 Internal Server Error
(APIServer pid=1) INFO:     192.168.1.253:51352 - "POST /v1/chat/completions HTTP/1.1" 500 Internal Server Error
(APIServer pid=1) INFO:     Shutting down
(APIServer pid=1) INFO:     Waiting for application shutdown.
(APIServer pid=1) INFO:     Application shutdown complete.
(APIServer pid=1) INFO:     Finished server process [1]
/usr/lib/python3.12/multiprocessing/resource_tracker.py:279: UserWarning: resource_tracker: There appear to be 4 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.12/multiprocessing/resource_tracker.py:279: UserWarning: resource_tracker: There appear to be 4 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
